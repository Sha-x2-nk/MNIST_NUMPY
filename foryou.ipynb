{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import urllib.request\n",
    "from MNIST_NN import *\n",
    "def load_dataset():\n",
    "    # Download the MNIST dataset files\n",
    "    url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    filenames = ['train-images-idx3-ubyte.gz', 'train-labels-idx1-ubyte.gz',\n",
    "                't10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz']\n",
    "\n",
    "    for filename in filenames:\n",
    "        if not os.path.exists(\"MNIST_DATASET/\"+filename):\n",
    "            urllib.request.urlretrieve(url + filename, \"MNIST_DATASET/\"+filename)\n",
    "\n",
    "    # Function to read the MNIST data files\n",
    "    def read_mnist_images(filename):\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "        return data.reshape(-1, 28*28)\n",
    "\n",
    "    def read_mnist_labels(filename):\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "        return data\n",
    "\n",
    "    # Load the training and test data\n",
    "    train_images = read_mnist_images('MNIST_DATASET/train-images-idx3-ubyte.gz')\n",
    "    train_labels = read_mnist_labels('MNIST_DATASET/train-labels-idx1-ubyte.gz')\n",
    "    test_images = read_mnist_images('MNIST_DATASET/t10k-images-idx3-ubyte.gz')\n",
    "    test_labels = read_mnist_labels('MNIST_DATASET/t10k-labels-idx1-ubyte.gz')\n",
    "    val_mask = np.arange(0,60000)\n",
    "    np.random.shuffle(val_mask)\n",
    "    val_images = train_images[val_mask[:2000]]\n",
    "    val_labels = train_labels[val_mask[:2000]]\n",
    "    train_images = train_images[val_mask[2000:]]\n",
    "    train_labels = train_labels[val_mask[2000:]]\n",
    "    return train_images, train_labels, val_images, val_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(p= 0.7315121964113247, reg= 0):\n",
    "    model = NeuralNetwork()\n",
    "    model.layers['l1'] = affineReLULayer(784, 2048,p_keep = p)\n",
    "    model.reg = reg\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model()\n",
    "train_images, train_labels, val_images, val_labels, test_images, test_labels= load_dataset()\n",
    "num_epochs = 20\n",
    "batch_size = 512\n",
    "best_acc = (0,0)\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1  iter:100  loss:1.8619595294637097  acc: 0.905511811023622  val_acc: 0.9495\n",
      "BEST VAL: 0.9495  TRAIN: 0.905511811023622\n",
      "epoch: 2  iter:100  loss:0.885945029531009  acc: 0.9566929133858267  val_acc: 0.9685\n",
      "BEST VAL: 0.9685  TRAIN: 0.9566929133858267\n",
      "epoch: 3  iter:100  loss:0.9310624217767237  acc: 0.9488188976377953  val_acc: 0.972\n",
      "BEST VAL: 0.972  TRAIN: 0.9488188976377953\n",
      "epoch: 4  iter:100  loss:0.25810678065670434  acc: 0.9822834645669292  val_acc: 0.9715\n",
      "BEST VAL: 0.9715  TRAIN: 0.9822834645669292\n",
      "epoch: 5  iter:100  loss:0.3540608326488518  acc: 0.9665354330708661  val_acc: 0.9755\n",
      "BEST VAL: 0.9755  TRAIN: 0.9665354330708661\n",
      "epoch: 6  iter:100  loss:0.18772505578771007  acc: 0.9881889763779528  val_acc: 0.976\n",
      "BEST VAL: 0.976  TRAIN: 0.9881889763779528\n",
      "epoch: 7  iter:100  loss:0.13220574679268438  acc: 0.9862204724409449  val_acc: 0.979\n",
      "BEST VAL: 0.979  TRAIN: 0.9862204724409449\n",
      "epoch: 8  iter:100  loss:0.19338101693037604  acc: 0.9822834645669292  val_acc: 0.975\n",
      "BEST VAL: 0.975  TRAIN: 0.9822834645669292\n",
      "epoch: 9  iter:100  loss:0.200082358217132  acc: 0.9822834645669292  val_acc: 0.979\n",
      "BEST VAL: 0.979  TRAIN: 0.9822834645669292\n",
      "epoch: 10  iter:100  loss:0.12066167424246875  acc: 0.9901574803149606  val_acc: 0.9745\n",
      "BEST VAL: 0.9745  TRAIN: 0.9901574803149606\n",
      "epoch: 11  iter:100  loss:0.21545454351783278  acc: 0.9822834645669292  val_acc: 0.9755\n",
      "BEST VAL: 0.9755  TRAIN: 0.9822834645669292\n",
      "epoch: 12  iter:100  loss:0.033929812836156724  acc: 0.9960629921259843  val_acc: 0.9775\n",
      "BEST VAL: 0.9775  TRAIN: 0.9960629921259843\n",
      "epoch: 13  iter:100  loss:0.04261852391188889  acc: 0.9940944881889764  val_acc: 0.9795\n",
      "BEST VAL: 0.9795  TRAIN: 0.9940944881889764\n",
      "epoch: 14  iter:100  loss:0.03141571117747581  acc: 0.9960629921259843  val_acc: 0.975\n",
      "BEST VAL: 0.975  TRAIN: 0.9960629921259843\n",
      "epoch: 15  iter:100  loss:0.07855442022242788  acc: 0.9881889763779528  val_acc: 0.9755\n",
      "BEST VAL: 0.9755  TRAIN: 0.9881889763779528\n",
      "epoch: 16  iter:100  loss:0.11565254509673444  acc: 0.9901574803149606  val_acc: 0.9765\n",
      "BEST VAL: 0.9765  TRAIN: 0.9901574803149606\n",
      "epoch: 17  iter:100  loss:0.19269560481715756  acc: 0.9862204724409449  val_acc: 0.98\n",
      "BEST VAL: 0.98  TRAIN: 0.9862204724409449\n",
      "epoch: 18  iter:100  loss:0.10260281102567902  acc: 0.9901574803149606  val_acc: 0.98\n",
      "BEST VAL: 0.98  TRAIN: 0.9901574803149606\n",
      "epoch: 19  iter:100  loss:0.17974439534584571  acc: 0.9862204724409449  val_acc: 0.9805\n",
      "BEST VAL: 0.9805  TRAIN: 0.9862204724409449\n",
      "epoch: 20  iter:100  loss:0.1044997451750783  acc: 0.9921259842519685  val_acc: 0.98\n",
      "BEST VAL: 0.98  TRAIN: 0.9921259842519685\n"
     ]
    }
   ],
   "source": [
    "total_iters = math.ceil(len(train_labels)/batch_size)\n",
    "train_images_loader = np.array_split(train_images,total_iters)\n",
    "train_labels_loader = np.array_split(train_labels, total_iters)\n",
    "for epoch in range(num_epochs):\n",
    "    for iter,(x_train,y_train) in enumerate(zip(train_images_loader, train_labels_loader)):\n",
    "        model.train()\n",
    "        y_pred,loss = model(x_train,y_train)\n",
    "        model.adamStep()\n",
    "\n",
    "        if (iter+1)%100 == 0:\n",
    "\n",
    "            predicted = np.argmax(y_pred, axis = 1)\n",
    "            train_acc = (predicted==y_train).sum()/y_train.shape[0]\n",
    "\n",
    "            model.eval()\n",
    "            y_pred = model(val_images)\n",
    "            predicted = np.argmax(y_pred, axis = 1)\n",
    "            val_acc = (predicted==val_labels).sum()/val_labels.shape[0]\n",
    "            print(f\"epoch: {epoch+1}  iter:{iter+1}  loss:{loss}  acc: {train_acc}  val_acc: {val_acc}\")\n",
    "\n",
    "            if val_acc>best_acc[0]:\n",
    "                best_model = model\n",
    "                print(f'BEST VAL: {val_acc}  TRAIN: {train_acc}')\n",
    "\n",
    "model = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9767\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    y_pred = model(test_images)\n",
    "    pred_classes = np.argmax(y_pred,axis = 1)\n",
    "    acc = (pred_classes==test_labels).sum()/test_labels.shape[0]\n",
    "    return acc\n",
    "print(test())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
